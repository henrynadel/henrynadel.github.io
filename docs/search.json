[
  {
    "objectID": "text_analysis.html",
    "href": "text_analysis.html",
    "title": "Analysing New York Times Headlines",
    "section": "",
    "text": "On this page I analyze a data set with headlines from all New York Times articles dating back to 1996. My analysis focuses on (1) frequent content words, (2) locations referenced, and (3) how often numbers and years appear in headlines.\nThis data was soruced from the NYTimes dataset in the RTextTools package."
  },
  {
    "objectID": "text_analysis.html#frequest-word-usage",
    "href": "text_analysis.html#frequest-word-usage",
    "title": "Analysing New York Times Headlines",
    "section": "Frequest Word Usage",
    "text": "Frequest Word Usage\n\ntitles_tokens &lt;- nyt |&gt;\n  transmute(\n    Title_clean = Title |&gt;\n      str_to_lower() |&gt;\n      str_replace_all(\"[^a-z\\\\s]\", \" \") |&gt;\n      str_replace_all(\"\\\\s+\", \" \") |&gt;\n      str_trim()\n  ) |&gt;\n  unnest_tokens(word, Title_clean, token = \"words\") |&gt;\n  anti_join(stop_words, by = \"word\") |&gt;\n  filter(str_detect(word, \"^[a-z]+$\"), nchar(word) &gt;= 3)\n\ntop_words &lt;- titles_tokens |&gt;\n  count(word, sort = TRUE) |&gt;\n  slice_head(n = 15)\n\n\n# Plot — Top content words\nggplot(top_words, aes(x = reorder(word, n), y = n)) +\n  geom_col() +\n  coord_flip() +\n  labs(\n    title = \"Most Frequent\n    VWords in NYT Headlines since 1996\",\n    x = \"Word\",\n    y = \"Count\"\n  ) +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\nThis bar chart shows the most common words in found in the headline column of the data set. It’s an interesting way to find many of the most common topics covered by the New York Times over the past three decades. Notably, the top three words stand distinctively above the rest in usage: Bush, Iraq, and War. this makes sense as all three of these words point to the same general event of President Bush’s decision to invade Iraq following 9/11. This makes sense as it was a large global event that toom place near the beginning of this data’s period of observation. These findings make an interesting claim about how extensively the war in Iraq penetrated the American news cycle."
  },
  {
    "objectID": "text_analysis.html#frequently-mentioned-places",
    "href": "text_analysis.html#frequently-mentioned-places",
    "title": "Analysing New York Times Headlines",
    "section": "Frequently Mentioned Places",
    "text": "Frequently Mentioned Places\nin this section I find the locations that are most frequestly refrenced by searcing for words that follow the preposition “in…”\n\nlocs &lt;- nyt |&gt;\n  transmute(\n    Title,\n    loc = str_extract_all(\n      Title,\n      \"(?&lt;=\\\\bin\\\\s)([A-Z][A-Za-z\\\\-]+(?:\\\\s[A-Z][A-Za-z\\\\-]+)*)\"\n    )\n  ) |&gt;\n  unnest(loc) |&gt;\n  mutate(loc = loc |&gt;\n           str_replace_all(\"\\\\s+\", \" \") |&gt;\n           str_trim()) |&gt;\n  count(loc, sort = TRUE) |&gt;\n  slice_head(n = 10)\n\n\n# Plot 2 — Top phrases following \"in \"\nggplot(locs, aes(x = reorder(loc, n), y = n)) +\n  geom_col() +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Phrases Following 'in' - NYT Headlines\",\n    x = \"Location phrase\",\n    y = \"Count\"\n  ) +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\nFollowing the previous section, it is unsurprising that far and away the most frequently mentioned location is Iraq, further emphasizing the impact of the war in Iraq on the american news cycle. Another interesting finding from this is a lack of reference to Africa or South America in the top 10 spots. Furthermore, New York and Florida stick out as the only U.S. states listed. It is worth noting that many of these names have much higher tallies when counting total uses. The specific criteria of words following “in” is meant to isolate the places where stories are taking place, opposed to total mentions."
  },
  {
    "objectID": "text_analysis.html#headlines-containing-numbers-years",
    "href": "text_analysis.html#headlines-containing-numbers-years",
    "title": "Analysing New York Times Headlines",
    "section": "Headlines Containing Numbers & Years",
    "text": "Headlines Containing Numbers & Years\n\ntitle_nums &lt;- nyt |&gt;\n  transmute(\n    Title,\n    has_number = str_detect(Title, \"\\\\b\\\\d{1,3}(?:,\\\\d{3})*(?:\\\\.\\\\d+)?\\\\b\"),\n    years_list = str_extract_all(Title, \"\\\\b(19|20)\\\\d{2}\\\\b\")\n  )\n\nprop_table &lt;- tibble(\n  metric = c(\"Headlines containing any number\"),\n  value  = c(mean(title_nums$has_number))\n) |&gt;\n  mutate(share = scales::percent(value)) |&gt;\n  select(metric, share)\n\n\n# Table — Share of headlines with numbers / percentages\nkable(\n  prop_table,\n  col.names = c(\"Metric\", \"Share of headlines\"),\n  caption = \"% of NYT headlines with numeric content\"\n)\n\n\n% of NYT headlines with numeric content\n\n\nMetric\nShare of headlines\n\n\n\n\nHeadlines containing any number\n11%\n\n\n\n\n\n\n# Table — Most mentioned years\nyears_top &lt;- title_nums |&gt;\n  select(years_list) |&gt;\n  unnest(years_list, keep_empty = FALSE) |&gt;\n  count(year = years_list, sort = TRUE) |&gt;\n  slice_head(n = 10)\n\nkable(\n  years_top,\n  col.names = c(\"Year\", \"Count\"),\n  caption = \"Top 10 years referenced in headlines\"\n)\n\n\nTop 10 years referenced in headlines\n\n\nYear\nCount\n\n\n\n\n2000\n37\n\n\n1998\n6\n\n\n2004\n3\n\n\n1964\n2\n\n\n1996\n2\n\n\n2003\n2\n\n\n1937\n1\n\n\n1940\n1\n\n\n1970\n1\n\n\n1972\n1\n\n\n\n\n\nIt’s interesting how much of this list is years before the period of observation from the data set beginning in 1996. This indicates a trend of using years in headlines more frequently when referring to events farther back in the past. It’s also worth noting the “Count” column, which shows that they year 2000 is mentioned by far the most frequently, and all but six years were mentioned only once.\nData Citation: R Core Team. (2020). NYTimes: a sample dataset containing labeled headlines from The New York Times. RTextTools. https://rdrr.io/cran/RTextTools/man/NYTimes.html"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Me",
    "section": "",
    "text": "Hi! My name is Henry Nadel. I am currently in my final year at Pitzer College where I study Environmental Analysis on a public policy track with an additional minor in Data Science. I am particularly interested in using data to inform public policy along with using graphing and GIS software to convey data in an accessible manner. When I’m not in the classroom I can usually be found outside running, climbing, or exploring one of California’s amazing parks.\nCurrently: Senior at Pitzer College\nMajor: Environmental Analysis; Minor: Data Science\nBased in: Claremont, CA\nOriginally from: Newton, MA"
  },
  {
    "objectID": "tidytuesday-1.html",
    "href": "tidytuesday-1.html",
    "title": "TidyTuesday - Himalayan Mountaineering",
    "section": "",
    "text": "The following data set was gathered and provided by TidyTuesday, linked here:\nhttps://github.com/rfordatascience/tidytuesday/blob/main/data/2025/2025-01-21/readme.md\nThe data was sourced from the Himalayan Database which keeps information on peaks and mountaineering expeditions that take place in the Himalayan Region. The full himalayan database catalog can be found here:\nhttps://www.himalayandatabase.com/index.html\nThe following graph attempts to compare the volume of expeditions per region listed in the data on all mountains exceeding 7,000 meters. This is done by joining the “peaks” and “expeditions” data sets, filtering for only peaks above 7,000m, and then counting the expeditions by region.\n\n# joining\nexped_tidy &lt;- exped_tidy |&gt; mutate(PEAKID = as.character(PEAKID))\npeaks_tidy &lt;- peaks_tidy |&gt; mutate(PEAKID = as.character(PEAKID))\n\n# count expeditions for peaks &gt;= 7000m \nexped_by_region &lt;- exped_tidy |&gt;\n  distinct(EXPID, PEAKID) |&gt;  \n  inner_join(\n    peaks_tidy |&gt; select(PEAKID, HEIGHTM, REGION_FACTOR),\n    by = \"PEAKID\"\n  ) |&gt;\n  filter(HEIGHTM &gt;= 7000) |&gt;\n  count(REGION_FACTOR, name = \"n_expeditions\") |&gt;\n  arrange(desc(n_expeditions))\n\nexped_by_region\n\n# A tibble: 6 × 2\n  REGION_FACTOR           n_expeditions\n  &lt;chr&gt;                           &lt;int&gt;\n1 Khumbu-Rolwaling-Makalu           356\n2 Manaslu-Ganesh                     96\n3 Annapurna-Damodar-Peri             90\n4 Dhaulagiri-Mukut                   45\n5 Kangchenjunga-Janak                28\n6 Langtang-Jugal                      2\n\n\n\n# ---- plot ----\nggplot(exped_by_region,\n       aes(x = forcats::fct_reorder(REGION_FACTOR, n_expeditions),\n           y = n_expeditions)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(\n    title = \"Number of Expeditions on ≥7000 m Peaks, by Region\",\n    subtitle = \"Himalayan Database (TidyTuesday 2025-01-21)\",\n    x = \"Region\",\n    y = \"Number of expeditions\"\n  ) +\n  theme_minimal(base_size = 12)"
  },
  {
    "objectID": "tidytuesday-2.html",
    "href": "tidytuesday-2.html",
    "title": "TidyTuesday - Gas Pricing",
    "section": "",
    "text": "The following data was provided by TidyTuesday, linked here:\nhttps://github.com/rfordatascience/tidytuesday/blob/main/data/2025/2025-07-01/readme.md\nThe data was sourced from the U.S. Energy Information Administration (EIA), which publishes average retail gasoline and diesel prices each Monday. The original data (including additional datasets) can be found at eia.gov/petroleum/gasdiesel\nThe following code averages out weekly reports to create average annual gasoline prices. Then, the data is graphed to create a visual display of the change in American gas pricing over time.\n\n# yearly average gasoline price\ngas_yearly &lt;- weekly_gas_prices |&gt;\n  filter(fuel == \"gasoline\", grade == \"all\", formulation == \"all\") |&gt;\n  mutate(year = year(date)) |&gt;\n  group_by(year) |&gt;\n  summarise(avg_price = mean(price, na.rm = TRUE), .groups = \"drop\") |&gt;\n  arrange(year)\n\nprint(gas_yearly, n = Inf)\n\n# A tibble: 33 × 2\n    year avg_price\n   &lt;dbl&gt;     &lt;dbl&gt;\n 1  1993      1.07\n 2  1994      1.08\n 3  1995      1.16\n 4  1996      1.24\n 5  1997      1.24\n 6  1998      1.07\n 7  1999      1.18\n 8  2000      1.52\n 9  2001      1.46\n10  2002      1.39\n11  2003      1.60\n12  2004      1.89\n13  2005      2.31\n14  2006      2.62\n15  2007      2.84\n16  2008      3.30\n17  2009      2.41\n18  2010      2.84\n19  2011      3.58\n20  2012      3.68\n21  2013      3.58\n22  2014      3.44\n23  2015      2.52\n24  2016      2.25\n25  2017      2.53\n26  2018      2.81\n27  2019      2.69\n28  2020      2.26\n29  2021      3.10\n30  2022      4.06\n31  2023      3.63\n32  2024      3.42\n33  2025      3.25\n\n\n\n# Plot\nggplot(gas_yearly, aes(x = year, y = avg_price, group = 1)) +\n  geom_line() +\n  geom_point() +\n  labs(\n    title = \"Average U.S. Gasoline Price by Year\",\n    x = \"Year\",\n    y = \"Average price (USD/gal)\"\n  ) +\n  scale_y_continuous(labels = scales::dollar_format()) +\n  scale_x_continuous(breaks = scales::pretty_breaks()) +\n  theme_minimal(base_size = 12)"
  },
  {
    "objectID": "Permutation_test.html",
    "href": "Permutation_test.html",
    "title": "Permutation_test",
    "section": "",
    "text": "In this project, I conduct a small simulation study using a permutation test to explore whether there is an association between warehouse construction and unemployment rates in Southern California between 1990 and 2023.\nSpecifically, I ask:\n    Is there a relationship between economic growth through warehouse construction and local unemployment levels in Los Angeles, San Bernardino, and Riverside Counties from 1990 to 2023?\nThis question is interesting because warehouse development is often seen as an engine of local job creation in the Inland Empire, but data can reveal whether such development truly corresponds with lower unemployment."
  },
  {
    "objectID": "Permutation_test.html#introduction",
    "href": "Permutation_test.html#introduction",
    "title": "Permutation_test",
    "section": "",
    "text": "In this project, I conduct a small simulation study using a permutation test to explore whether there is an association between warehouse construction and unemployment rates in Southern California between 1990 and 2023.\nSpecifically, I ask:\n    Is there a relationship between economic growth through warehouse construction and local unemployment levels in Los Angeles, San Bernardino, and Riverside Counties from 1990 to 2023?\nThis question is interesting because warehouse development is often seen as an engine of local job creation in the Inland Empire, but data can reveal whether such development truly corresponds with lower unemployment."
  },
  {
    "objectID": "Permutation_test.html#data-used",
    "href": "Permutation_test.html#data-used",
    "title": "Permutation_test",
    "section": "Data Used:",
    "text": "Data Used:\nWarehouseCITY dataset1 — total new warehouse square footage built per year (1990–2023).\nLocal Area Unemployment Statistics (LAUS) from the U.S. Bureau of Labor Statistics2 — annual unemployment rate for the same region.\nBoth of the above data sets were sourced and trimmed down to only the fields relevant to this question during a an old project I had been working on.\n\n\nCode\nnew_sqft_by_unemployment &lt;- tribble(\n  ~Year, ~Building_sqft, ~Unemployment_rate,\n  1990, 33117000, 5.5,\n  1991, 18049000, 7.7,\n  1992, 13342000, 9.4,\n  1993, 5496000, 9.6,\n  1994, 9896000, 8.6,\n  1995, 12322000, 7.6,\n  1996, 13340000, 7.4,\n  1997, 18313000, 6.2,\n  1998, 40683000, 5.8,\n  1999, 37391000, 5.1,\n  2000, 43402000, 4.9,\n  2001, 43587000, 5.3,\n  2002, 29485000, 6.4,\n  2003, 32292000, 6.5,\n  2004, 36145000, 5.9,\n  2005, 37454000, 5.0,\n  2006, 36564000, 4.5,\n  2007, 36654000, 5.0,\n  2008, 22418000, 7.3,\n  2009, 12283000, 11.6,\n  2010, 4915000, 12.4,\n  2011, 8212000, 11.9,\n  2012, 13895000, 10.6,\n  2013, 18823000, 9.2,\n  2014, 23496000, 7.7,\n  2015, 29009000, 6.3,\n  2016, 28887000, 5.2,\n  2017, 37838000, 4.7,\n  2018, 45736000, 4.2,\n  2019, 30398000, 4.1,\n  2020, 37704000, 11.1,\n  2021, 43896000, 8.0,\n  2022, 44088000, 4.5,\n  2023, 30926000, 4.7\n)"
  },
  {
    "objectID": "Permutation_test.html#visualizing-the-original-relationship",
    "href": "Permutation_test.html#visualizing-the-original-relationship",
    "title": "Permutation_test",
    "section": "Visualizing the Original Relationship",
    "text": "Visualizing the Original Relationship\nThe following scatterplot displays the annual relationship between new warehouse square footage and unemployment rate. Each point represents one year between 1990 and 2023, with a linear trend line to visualize direction.\n\n\nCode\nnew_sqft_by_unemployment |&gt;\n  ggplot(aes(x = Building_sqft, y = Unemployment_rate)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Building Square Footage vs. Unemployment Rate\",\n       x = \"New building sq.ft. by year\",\n       y = \"Unemployment rate (%)\") +\n  scale_x_continuous(labels = comma_format(accuracy = 1)) +\n  theme_minimal()\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nIn this graph we see years with higher construction volumes tend to have lower unemployment, suggesting a potential negative correlation. However, to test whether this observed relationship could have arisen by random chance, we perform a permutation test."
  },
  {
    "objectID": "Permutation_test.html#setting-up-the-permutation-test",
    "href": "Permutation_test.html#setting-up-the-permutation-test",
    "title": "Permutation_test",
    "section": "Setting Up the Permutation Test",
    "text": "Setting Up the Permutation Test\nOur hypotheses are:\n  Null hypothesis (H₀): There is no association between warehouse construction and unemployment rate.\n  Alternative hypothesis (H₁): Higher levels of warehouse construction correspond with lower unemployment.\nThe test statistic will be the correlation coefficient between Building_sqft and Unemployment_rate."
  },
  {
    "objectID": "Permutation_test.html#simulation-design",
    "href": "Permutation_test.html#simulation-design",
    "title": "Permutation_test",
    "section": "Simulation Design",
    "text": "Simulation Design\nI’ll first write a small function that computes a correlation after shuffling one variable. Then I’ll use a map() variant to repeat this process thousands of times, generating the null distribution.\n\n\nCode\n# Function to compute one permuted correlation\n# perm_cor for permutation correlation\nperm_cor &lt;- function(df) {\ncor(df$Building_sqft, sample(df$Unemployment_rate))\n}\n\n# Run simulations using map_dbl()\n\nset.seed(47)\nn_sims &lt;- 10000\nr_perm &lt;- map_dbl(1:n_sims, ~ perm_cor(new_sqft_by_unemployment))\n\n# Observed correlation in original data\nr_obs &lt;- cor(new_sqft_by_unemployment$Building_sqft,\nnew_sqft_by_unemployment$Unemployment_rate)\n\n# Two-sided p-value\np_val &lt;- mean(abs(r_perm) &gt;= abs(r_obs))\n\ntibble(observed_r = r_obs, p_value_two_sided = p_val)\n\n\n# A tibble: 1 × 2\n  observed_r p_value_two_sided\n       &lt;dbl&gt;             &lt;dbl&gt;\n1     -0.736                 0"
  },
  {
    "objectID": "Permutation_test.html#visualizing-the-permutation-distribution",
    "href": "Permutation_test.html#visualizing-the-permutation-distribution",
    "title": "Permutation_test",
    "section": "Visualizing the Permutation Distribution",
    "text": "Visualizing the Permutation Distribution\nThe histogram below shows the distribution of correlation coefficients obtained under the null hypothesis (no relationship). The vertical red line marks the observed correlation from the real data.\n\n\nCode\ntibble(r = r_perm) |&gt;\nggplot(aes(x = r)) +\ngeom_histogram(bins = 40, fill = \"skyblue\", color = \"white\") +\ngeom_vline(xintercept = r_obs, color = \"red\", linewidth = 1.2) +\nlabs(\ntitle = \"Permutation Test for Correlation\",\nsubtitle = paste0(\"Observed r = \", round(r_obs, 3),\n\" | p(two-sided) = \", signif(p_val, 3)),\nx = \"Permuted correlation (null distribution)\",\ny = \"Count\"\n) +\ntheme_minimal()\n\n\n\n\n\n\n\n\n\nThe histogram is centered around 0, as expected under the null hypothesis. The observed correlation of approximately −0.74 lies far in the left tail of the distribution. Out of 10,000 permutations, none produced a correlation as extreme, implying a very small p-value and evidence against the null hypothesis."
  },
  {
    "objectID": "Permutation_test.html#discussion",
    "href": "Permutation_test.html#discussion",
    "title": "Permutation_test",
    "section": "Discussion",
    "text": "Discussion\nThis simulation suggests a negative relationship between warehouse construction and unemployment in the Los Angeles–San Bernardino–Riverside region from 1990 to 2023, meaning that in years when more warehouse square footage was built, unemployment rates tended to be lower. However, it’s important to note that while the null hypothesis was disproved, that doesn’t mean the initial data shown at the top has a strong linear correlation (which is why this data got scrapped from the project i was originally using it for)\nFurthermore, this result does not imply direct causation. Both variables may be influenced by larger economic cycles (e.g., recessions in 2008 and 2020). Still, this permutation study demonstrates how randomization methods can assess relationships between data while avoiding distributional assumptions."
  },
  {
    "objectID": "Permutation_test.html#footnotes",
    "href": "Permutation_test.html#footnotes",
    "title": "Permutation_test",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPhillips, S. A., & McCarthy, M. C. (2024). Warehouse CITY: An open data product for evaluating warehouse land-use in Southern California. Environment and Planning B, 51(8), 1965–1973. https://doi.org/10.1177/23998083241262553↩︎\nU.S. Bureau of Labor Statistics. (2024). Local Area Unemployment Statistics (LAUS). https://www.bls.gov/lau/↩︎"
  }
]